{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenge of the social network project is that a simple keyword-based filtering method is only limited to some sensitive words. This section is about filtering spam messages from the social network platform using machine learning algorithm. To improve the spam message classifier, I obtained a realistic dataset of SMS text messages from the [UCI datasets](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection), which is also already downloaded for you under the same directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sample size:  5574 \n",
      "\n",
      "0 ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\n",
      "\n",
      "1 ham\tOk lar... Joking wif u oni...\n",
      "\n",
      "\n",
      "2 spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "\n",
      "\n",
      "3 ham\tU dun say so early hor... U c already then say...\n",
      "\n",
      "\n",
      "4 ham\tNah I don't think he goes to usf, he lives around here though\n",
      "\n",
      "\n",
      "5 spam\tFreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\n",
      "\n",
      "\n",
      "6 ham\tEven my brother is not like to speak with me. They treat me like aids patent.\n",
      "\n",
      "\n",
      "7 ham\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
      "\n",
      "\n",
      "8 spam\tWINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
      "\n",
      "\n",
      "9 spam\tHad your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = [line.rstrip() for line in open('smsspamcollection/SMSSpamCollection')]\n",
    "print('Total sample size: ', len(messages), '\\n')\n",
    "# print first 10 messages\n",
    "for message_no, message in enumerate(messages[:10]):\n",
    "    print(message_no, message)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "messages = pd.read_csv('smsspamcollection/SMSSpamCollection', sep='\\t',\n",
    "                           names=[\"label\", \"message\"])\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      message                                                               \n",
       "        count unique                                                top freq\n",
       "label                                                                       \n",
       "ham      4825   4516                             Sorry, I'll call later   30\n",
       "spam      747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check how many spammer and hammer\n",
    "messages.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "# Show some stop word examples\n",
    "stopwords.words('english')[0:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_process(message):\n",
    "    \"\"\"\n",
    "    Read in a segment of text message, then performs the following pre-processing steps:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in message if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, jurong, point, crazy, Available, bugis, n...\n",
       "1                       [Ok, lar, Joking, wif, u, oni]\n",
       "2    [Free, entry, 2, wkly, comp, win, FA, Cup, fin...\n",
       "3        [U, dun, say, early, hor, U, c, already, say]\n",
       "4    [Nah, dont, think, goes, usf, lives, around, t...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on a small set of samples:\n",
    "messages['message'].head(5).apply(text_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Total sample size:  5572 \n",
      " Total # of training set:  4457 \n",
      " Total # of test set:  1115\n"
     ]
    }
   ],
   "source": [
    "# split the sample into training set (80%) and cross-validation set (20%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "msg_train, msg_test, label_train, label_test = \\\n",
    "train_test_split(messages['message'], messages['label'], test_size=0.2)\n",
    "print(\" Total sample size: \", len(msg_train) + len(msg_test), \"\\n Total # of training set: \", len(msg_train),\\\n",
    "      \"\\n Total # of test set: \", len(msg_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# convert to bag of words\n",
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(msg_train)\n",
    "# Print total number of vocab words\n",
    "#print(len(bow_transformer.vocabulary_))\n",
    "#print(bow_transformer.vocabulary_.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Networking 2573\n",
      "technical 9098\n",
      "support 8995\n",
      "associate 4214\n",
      "long 6930\n",
      "applebees 4137\n",
      "fucking 5931\n",
      "take 9049\n",
      "Hows 1965\n",
      "queen 8050\n",
      "going 6054\n"
     ]
    }
   ],
   "source": [
    "# Print top 10 word counts\n",
    "i = 10;\n",
    "for key, value in bow_transformer.vocabulary_.items():\n",
    "    print(key, value)\n",
    "    i = i -1\n",
    "    if i < 0: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimension of bag-of-word matrix for all messages in training set:  (4457,)\n",
      "The dimension of bag-of-word matrix for all messages in test set:  (1115,)\n"
     ]
    }
   ],
   "source": [
    "# construct the bag-of-word maxtrix using all SMS messages in training set and test set\n",
    "msg_bow_train = bow_transformer.transform(msg_train)\n",
    "msg_bow_test = bow_transformer.transform(msg_test)\n",
    "print(\"The dimension of bag-of-word matrix for all messages in training set: \", msg_train.shape)\n",
    "print(\"The dimension of bag-of-word matrix for all messages in test set: \", msg_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print one message body:  Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "The dimension of bag-of-word vector for No.2 message:  (1, 10077)\n",
      "Print key-value pairs of BOW for message 2: \n",
      "   (0, 60)\t1\n",
      "  (0, 347)\t1\n",
      "  (0, 354)\t1\n",
      "  (0, 364)\t1\n",
      "  (0, 738)\t1\n",
      "  (0, 1334)\t1\n",
      "  (0, 1577)\t2\n",
      "  (0, 1672)\t1\n",
      "  (0, 2425)\t1\n",
      "  (0, 3449)\t1\n",
      "  (0, 4140)\t1\n",
      "  (0, 4926)\t1\n",
      "  (0, 5558)\t2\n",
      "  (0, 5765)\t1\n",
      "  (0, 8054)\t1\n",
      "  (0, 8090)\t1\n",
      "  (0, 8136)\t1\n",
      "  (0, 9250)\t1\n",
      "  (0, 9406)\t1\n",
      "  (0, 9763)\t1\n",
      "  (0, 9798)\t1\n"
     ]
    }
   ],
   "source": [
    "# let's see what it's doing using one sample message\n",
    "message2 = msg_train[2]\n",
    "print(\"Print one message body: \",message2)\n",
    "bow2 = bow_transformer.transform([message2])\n",
    "print(\"The dimension of bag-of-word vector for No.2 message: \", bow2.shape)\n",
    "print(\"Print key-value pairs of BOW for message 2: \\n\", bow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of inverted document frequency in the traning set:  (10077,)\n",
      "Print details:  [ 8.01616115  8.30384323  8.70930833 ...,  8.70930833  7.20523094\n",
      "  8.70930833]\n"
     ]
    }
   ],
   "source": [
    "# calculate the IDF for traning set and test set\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer_train = TfidfTransformer().fit(msg_bow_train)\n",
    "tfidf_transformer_test = TfidfTransformer().fit(msg_bow_test)\n",
    "print(\"Dimension of inverted document frequency in the traning set: \", tfidf_transformer_train.idf_.shape)\n",
    "print(\"Print details: \", tfidf_transformer_train.idf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of TF-IDF matrix in the traning set:  (4457, 10077)\n"
     ]
    }
   ],
   "source": [
    "# now calculate the TF-IDF maxtrix based on the bag-of-word counts (TF) and IDF \n",
    "# the dimension should be consistent with messages_bow\n",
    "# the first index refers to the total number of messages, \n",
    "# and the second index the total number of unique words that appear in the sample\n",
    "msg_tfidf_train = tfidf_transformer_train.transform(msg_bow_train)\n",
    "msg_tfidf_test = tfidf_transformer_test.transform(msg_bow_test)\n",
    "print(\"Dimension of TF-IDF matrix in the traning set: \", msg_tfidf_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainning a Spam Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: fit the model with the training data\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_classifier = MultinomialNB().fit(msg_tfidf_train, label_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'ham' ..., 'spam' 'ham' 'ham']\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        ham       0.96      1.00      0.98       957\n",
      "       spam       1.00      0.75      0.86       158\n",
      "\n",
      "avg / total       0.97      0.97      0.96      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = spam_classifier.predict(msg_tfidf_test)\n",
    "print(test_predictions)\n",
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(label_test, test_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
